{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is dedicated to creating features for our heart rate prediction model. We add a lot of features which are partly inspired by the cycing domain (like trainingload, 'threshold power', etc.), but also features which are more explorative in nature. The relation of these features with our target variable will be explored in a next notebook **3. Feature exploration and selection.ipynb**\n",
    "\n",
    "First we recap some of the learings of our notebook **0. Data exploration.ipynb**\n",
    "\n",
    "**Learnings from 0. Data exploration.ipynb**\n",
    "\n",
    "We know that heart rate runs smoother than power (watts). We have also seen that heart rate is lagging an increase or decrease in power. Also we observed something which is called cardiac drift. This means that overtime heart rate tends to increase even if power stays constant. A lot of factors play a role here which cause heart rate to drift upwards (e.g. hydration, muscle recruitment, drop in stroke volume, etc.) which we broadly define as \"fatigue\". We also observe that heart rate goes up after consequtive intervals even though power remains rather constant during the intervals. This also shows we should take a time effect into account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is organised as follows:\n",
    "* Read in data from our previous notebook **1. Data processing.ipynb**\n",
    "* Cycling specific ride file derived features\n",
    "* Data driven features\n",
    "     * Cumulative moving averages\n",
    "     * Lagged variables\n",
    "     * Simple moving averages\n",
    "     * Deltas on moving averages\n",
    "     * Exponentially weighted moving averages\n",
    "     * Rolling standard deviations\n",
    "     * Extra possible related variables\n",
    "* Cycling (training)meta data features\n",
    "     * Cycling ride related features\n",
    "     * Cycling (training)meta data features\n",
    "     * (Cycling) (training)meta data indexed features\n",
    "     \n",
    "Note: We make extensive use of a function to reduce memory everytime new features are created to avoid memory issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "import gc\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import function to reduce memory during processing\n",
    "from reduce_memory import reduce_mem_usage\n",
    "\n",
    "# visualisations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 154.81 MB\n",
      "Decreased by 50.0%\n"
     ]
    }
   ],
   "source": [
    "# read in the file and preprocess\n",
    "\n",
    "def read_file(filename):\n",
    "    '''\n",
    "    Returns a DataFrame for further processing\n",
    "\n",
    "            Parameters:\n",
    "                    filename: (str) pickle object name\n",
    "                    \n",
    "            Returns:\n",
    "                    pd.DataFrame: pandas DataFrame for further processing\n",
    "    '''        \n",
    "    df = pd.read_pickle(filename)\n",
    "    \n",
    "    df['secs'] = df.groupby('filename').cumcount()+1\n",
    "    \n",
    "    df.sort_values(['filename', 'secs'], ascending=[True, True]).reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    df = reduce_mem_usage(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_raw = read_file('df_modelset_rider1.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycling specific features which are in the ride files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate two new features using the following formula:\n",
    "\n",
    "Power = Torque x Rotation Speed \n",
    "\n",
    "We calculate these two new features. Rotation speed in this equation is in radians/second. Convert RPM to radians/second by multiplying 2 x Pi / 60 (= 0.1047). Torque is in Newton-Meters (Nm)\n",
    "\n",
    "Example: rider is riding at 400 Watts at and riding with a cadence of 100 RPM, the rotation speed is (100 RPM) x (0.1047 rad/sec/RPM) = 10.47 rad/sec. The applied torque is then (400 Watts) / (10.47 rad/sec) = 38.20 Nm. This torque is applied to the cranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 170.29 MB\n",
      "Decreased by 21.4%\n"
     ]
    }
   ],
   "source": [
    "# Before continuing we make a small correction to the watts and cadence. If watts is zero, cadence will be put to zero. \n",
    "# Also when cadence is zero watts will be put to zero\n",
    "\n",
    "df_raw['cad'] = np.where((df_raw.watts==0) & (df_raw.cad>0), 0, df_raw.cad)\n",
    "df_raw['watts'] = np.where((df_raw.watts>0) & (df_raw.cad==0), 0, df_raw.watts)\n",
    "\n",
    "# calculate torque at crank and rotational speed\n",
    "\n",
    "def add_simple_cycling_features(df):\n",
    "    df['rotation_speed'] = np.round(((2*math.pi)/60)*df['cad'],2)\n",
    "    df['torque'] = np.round(df['watts']/df['rotation_speed'],2)\n",
    "    df['torque'] = df['torque'].fillna(0)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df\n",
    "\n",
    "df_raw = add_simple_cycling_features(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data driven features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 394.76 MB\n",
      "Decreased by 37.8%\n"
     ]
    }
   ],
   "source": [
    "# for variables with positive values we add some data transformations\n",
    "\n",
    "transform_cols = ['watts','secs','cad','torque','rotation_speed']\n",
    "\n",
    "for col in transform_cols:\n",
    "    df_raw['log_' + col] = np.log1p(df_raw[col])\n",
    "    df_raw['sqrt_' + col] = np.sqrt(df_raw[col])\n",
    "    df_raw['exp_' + col] = df_raw[col].apply(lambda x: x**(2))\n",
    "    df_raw['cub_' + col] = df_raw[col].apply(lambda x: x**(3))\n",
    "\n",
    "df_raw = reduce_mem_usage(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative moving averages (CMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 464.42 MB\n",
      "Decreased by 13.0%\n"
     ]
    }
   ],
   "source": [
    "columns_cum = ['watts','cad','rotation_speed'] #note we did not includr torque due to overflow (the result can not be stored within the finite 32-bit float or 64-bit double)\n",
    "\n",
    "for col in columns_cum:\n",
    "    df_raw['cum_total_' + col] =  np.round((df_raw.groupby('filename')[col].apply(lambda x: x.cumsum())).astype(int),0)\n",
    "    df_raw['cum_average_' + col] = np.round((df_raw.groupby('filename')[col].apply(lambda x: x.cumsum())/df_raw.secs),0)\n",
    "\n",
    "df_raw = reduce_mem_usage(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 665.67 MB\n",
      "Decreased by 24.6%\n"
     ]
    }
   ],
   "source": [
    "# for variables with positive values we add some data transformations\n",
    "\n",
    "columns_cum = [col for col in df_raw.columns if 'cum_' in col]\n",
    "\n",
    "for col in columns_cum:\n",
    "    df_raw['log_' + col] = np.log1p(df_raw[col])\n",
    "    df_raw['sqrt_' + col] = np.sqrt(df_raw[col])\n",
    "    df_raw['exp_' + col] = df_raw[col].apply(lambda x: x**(2))\n",
    "\n",
    "df_raw = reduce_mem_usage(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1290.09 MB\n",
      "Decreased by 30.2%\n"
     ]
    }
   ],
   "source": [
    "lags = range(5, 61, 5)\n",
    "#leads = range(-60, -4, 5)\n",
    "\n",
    "cols = ['watts','torque','cad','rotation_speed','slope']\n",
    "\n",
    "for i in lags:\n",
    "    for col in cols:\n",
    "        shifted = df_raw.groupby(\"filename\")[col].shift(i).to_frame()\n",
    "        df_raw = pd.merge(df_raw, shifted.rename(columns=lambda x: str(i)+\"s_lag_\"+str(col)), left_index=True, right_index=True, how='left')\n",
    "\n",
    "df_raw = reduce_mem_usage(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple moving averages: each period has a similar weight (1/n) (SMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1754.50 MB\n",
      "Decreased by 44.3%\n"
     ]
    }
   ],
   "source": [
    "window_range = range(5, 61, 5)\n",
    "\n",
    "cols = ['watts','torque','cad','rotation_speed','slope']\n",
    "\n",
    "for i in window_range:\n",
    "    for col in cols:\n",
    "        sma = df_raw.groupby(\"filename\")[col].rolling(window=i, adjust=False).mean().to_frame().droplevel(level=[0])\n",
    "        df_raw = pd.merge(df_raw, sma.rename(columns=lambda x: str(i)+\"s_sma_\"+ str(col)), left_index=True, right_index=True, how='left')\n",
    "\n",
    "# reduce memory usage\n",
    "df_raw = reduce_mem_usage(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple deltas for up to 10 seconds max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2064.12 MB\n",
      "Decreased by 18.4%\n"
     ]
    }
   ],
   "source": [
    "window_range = range(1, 11, 1)\n",
    "\n",
    "cols = ['watts','torque','cad','rotation_speed']\n",
    "\n",
    "for i in window_range:\n",
    "    for col in cols:\n",
    "        sma = (df_raw[col]-df_raw[col].shift(i).where(df_raw.filename.eq(df_raw.filename.shift(i)))).to_frame()\n",
    "        df_raw = pd.merge(df_raw, sma.rename(columns=lambda x: str(i)+\"s_delta_\"+ str(col)), left_index=True, right_index=True, how='left')\n",
    "\n",
    "# reduce memory usage\n",
    "df_raw = reduce_mem_usage(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2249.88 MB\n",
      "Decreased by 19.9%\n"
     ]
    }
   ],
   "source": [
    "# Add rolling means up to 30 seconds to show rolling acceleration for '1s_delta_watts' from 5 to 30 sec\n",
    "window_range = range(5, 31, 5)\n",
    "\n",
    "cols = ['1s_delta_watts','1s_delta_torque','1s_delta_rotation_speed','1s_delta_cad']\n",
    "\n",
    "for i in window_range:\n",
    "    for col in cols:\n",
    "        sma = df_raw.groupby(\"filename\")[col].rolling(window=i, adjust=False).mean().to_frame().droplevel(level=[0])\n",
    "        df_raw = pd.merge(df_raw, sma.rename(columns=lambda x: str(i)+\"s_\"+ str(col)+\"_mean\"), left_index=True, right_index=True, how='left')\n",
    "\n",
    "# reduce memory usage\n",
    "df_raw = reduce_mem_usage(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential moving averages: last period has 2/n+1 (alpha) importance, previous period has 1 - 2/n+1 importance (1-alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2714.30 MB\n",
      "Decreased by 33.9%\n"
     ]
    }
   ],
   "source": [
    "window_range = range(5, 61, 5)\n",
    "\n",
    "cols = ['watts','torque','cad','rotation_speed','slope']\n",
    "\n",
    "for i in window_range:\n",
    "    for col in cols:\n",
    "        ewma = df_raw.groupby('filename')[col].apply(lambda x: x.ewm(span=i, adjust=False).mean()).to_frame()\n",
    "        df_raw = pd.merge(df_raw, ewma.rename(columns=lambda x: str(i)+\"s_ewma_\"+ str(col)), left_index=True, right_index=True, how='left')\n",
    "    \n",
    "## reduce memory usage\n",
    "df_raw = reduce_mem_usage(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMA on standard deviation of watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2807.19 MB\n",
      "Decreased by 9.0%\n"
     ]
    }
   ],
   "source": [
    "window_range = range(5, 61, 5)\n",
    "\n",
    "for i in window_range:\n",
    "    \n",
    "    stds = df_raw.groupby(\"filename\").watts.rolling(window=i, adjust=False).std().to_frame().droplevel(level=[0])\n",
    "    df_raw = pd.merge(df_raw, stds.rename(columns=lambda x: str(i)+\"s_std_watts\"), left_index=True, right_index=True, how='left')\n",
    "\n",
    "# reduce memory usage\n",
    "df_raw = reduce_mem_usage(df_raw)\n",
    "#ewstd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional SMA variable for zero watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2903.94 MB\n",
      "Decreased by 9.1%\n"
     ]
    }
   ],
   "source": [
    "df_raw['dummy_zero_watts'] = np.where(df_raw.watts==0,1,0)\n",
    "\n",
    "window_range = range(5, 61, 5)\n",
    "\n",
    "for i in window_range:\n",
    "    \n",
    "    sma = df_raw.groupby(\"filename\").dummy_zero_watts.rolling(window=i, adjust=False).mean().to_frame().droplevel(level=[0])\n",
    "    df_raw = pd.merge(df_raw, sma.rename(columns=lambda x: str(i)+\"s_sma_dummy_watts\"), left_index=True, right_index=True, how='left')\n",
    "\n",
    "    # reduce memory usage\n",
    "df_raw = reduce_mem_usage(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free memory\n",
    "\n",
    "del ewma, shifted, sma, stds\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycling (training)meta data features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the notebook we add cycling specific features\n",
    "\n",
    "First we calculate two features ourselves based on the second by second data:\n",
    "\n",
    "* Skiba XPower\n",
    "* NP (Normalized Power)\n",
    "\n",
    "Validation of the calculation can be found in notebook **Additional Replicating xPower Python code.ipynb**\n",
    "\n",
    "Moreover we add meta level features related to the athletes ability to produce power, aggregate ride metrics and training stress/load metrics. References for these variables can be found in the literature section of notebook **0. Data exploration.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycling ride related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time processing 0:08:36.683549\n",
      "Time processing 0:17:09.942277\n"
     ]
    }
   ],
   "source": [
    "# We fill the zero values in our 25s SMA so we can easily define our first valid rolling 25s value starting point. Since these NaNs only appear in the first 25 secs of the files this is not a problem\n",
    "# Inspired and modified from: https://stackoverflow.com/questions/36923494/pandas-dataframe-use-previous-row-value-for-complicated-if-conditions-to-deter\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "df_part = df_raw[['filename','secs','25s_sma_watts','30s_sma_watts']]\n",
    "\n",
    "df_part['25s_sma_watts_fill'] =  df_part['25s_sma_watts'].fillna(0)\n",
    "df_part['30s_sma_watts_fill'] =  df_part['30s_sma_watts'].fillna(0)\n",
    "\n",
    "# define period for calculating xpower. This is 25 secs\n",
    "n = 25\n",
    "\n",
    "def apply_func_decorator(func):\n",
    "    prev_row = {}\n",
    "    def wrapper(curr_row, **kwargs):\n",
    "        val = func(curr_row, prev_row)\n",
    "        prev_row.update(curr_row)\n",
    "        prev_row['xPower_EMA'] = val\n",
    "        return val\n",
    "    return wrapper\n",
    "\n",
    "@apply_func_decorator\n",
    "def running_total(curr_row, prev_row):\n",
    "    return np.where(prev_row.get('25s_sma_watts_fill')==0, curr_row['25s_sma_watts_fill'], np.round((curr_row['25s_sma_watts_fill'] - prev_row.get('xPower_EMA', 0))*(2/(n+1)) + prev_row.get('xPower_EMA', 0),2))\n",
    "\n",
    "df_raw_1 = pd.DataFrame()\n",
    "\n",
    "for i in df_part.filename.unique():\n",
    "    df_init = df_part.loc[df_part.filename==i]\n",
    "    df_init['xPower_EMA'] = df_init.apply(running_total, axis=1)\n",
    "    df_raw_1 = df_raw_1.append(df_init, ignore_index=True)\n",
    "    \n",
    "df_raw_1.drop(columns=['25s_sma_watts','25s_sma_watts_fill'], inplace=True)\n",
    "\n",
    "print('Time processing', datetime.now()-start_time)\n",
    "\n",
    "# define period for calculating NP. This is 30 secs\n",
    "n = 30\n",
    "\n",
    "def apply_func_decorator(func):\n",
    "    prev_row = {}\n",
    "    def wrapper(curr_row, **kwargs):\n",
    "        val = func(curr_row, prev_row)\n",
    "        prev_row.update(curr_row)\n",
    "        prev_row['NP_EMA'] = val\n",
    "        return val\n",
    "    return wrapper\n",
    "\n",
    "@apply_func_decorator\n",
    "def running_total(curr_row, prev_row):\n",
    "    return np.where(prev_row.get('30s_sma_watts_fill')==0, curr_row['30s_sma_watts_fill'], np.round((curr_row['30s_sma_watts_fill'] - prev_row.get('NP_EMA', 0))*(2/(n+1)) + prev_row.get('NP_EMA', 0),2))\n",
    "\n",
    "df_raw_2 = pd.DataFrame()\n",
    "\n",
    "for i in df_part.filename.unique():\n",
    "    df_init = df_part.loc[df_part.filename==i]\n",
    "    df_init['NP_EMA'] = df_init.apply(running_total, axis=1)\n",
    "    df_raw_2 = df_raw_2.append(df_init, ignore_index=True)\n",
    "\n",
    "df_raw_2.drop(columns=['30s_sma_watts','30s_sma_watts_fill'], inplace=True)    \n",
    "    \n",
    "print('Time processing', datetime.now()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2759.42 MB\n",
      "Decreased by 1.7%\n"
     ]
    }
   ],
   "source": [
    "# merge features to one another before we merge it as one file to df_raw\n",
    "\n",
    "df_cycling_EMA = pd.merge(df_raw_1[['filename','secs','xPower_EMA']], df_raw_2[['filename','secs','NP_EMA']], on =['filename','secs'], how = 'left')\n",
    "\n",
    "# correction on the first row of each file since for the first row of a new file the value was calculated using the previous file\n",
    "df_cycling_EMA.loc[df_cycling_EMA.groupby('filename')['NP_EMA'].head(1).index, 'NP_EMA'] = 0\n",
    "df_cycling_EMA.loc[df_cycling_EMA.groupby('filename')['xPower_EMA'].head(1).index, 'xPower_EMA'] = 0\n",
    "\n",
    "# merge features to df_raw\n",
    "df_raw = pd.merge(df_raw, df_cycling_EMA, on =['filename','secs'], how = 'left')\n",
    "\n",
    "# garbage collect\n",
    "del df_raw_1, df_raw_2, df_init, df_part, df_cycling_EMA\n",
    "gc.collect()\n",
    "\n",
    "# reduce memory usage\n",
    "df_raw = reduce_mem_usage(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycling (training)meta data features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add two files. (1) One that is related to training load / CP and (2) one that is related to ride summary statistics. Note: These files were created using notebook **0. Data exploration.ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add training load information from PMC\n",
    "\n",
    "def read_file_PMC():\n",
    "    df = pd.read_pickle('df_PMC_CP.pkl')\n",
    "    df.reset_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "df_PMC_CP = read_file_PMC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2825.21 MB\n",
      "Decreased by 6.0%\n"
     ]
    }
   ],
   "source": [
    "# make date format column in df_raw to merge with df_PMC data\n",
    "\n",
    "df_raw['Date'] = df_raw['date'].astype(str).apply(lambda x: x.split('-')[1]) + \"/\" + df_raw['date'].astype(str).apply(lambda x: x.split('-')[2]) + \"/\" + df_raw['date'].astype(str).apply(lambda x: x.split('-')[0])\n",
    "\n",
    "# merge the PMC data to df_raw\n",
    "df_raw = pd.merge(df_raw, df_PMC_CP, how='left', on=['Date'])\n",
    "\n",
    "# reduce memory usage\n",
    "df_raw = reduce_mem_usage(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2960.67 MB\n",
      "Decreased by 7.8%\n"
     ]
    }
   ],
   "source": [
    "# read in summary statistics\n",
    "\n",
    "def read_file_activities_summary():\n",
    "    df = pd.read_pickle('df_summary_statistics.pkl')\n",
    "    return df\n",
    "\n",
    "df_summary_statistics = read_file_activities_summary()\n",
    "\n",
    "# merge the summary statistics data to df_raw\n",
    "df_raw = pd.merge(df_raw, df_summary_statistics, how='left', on=['date','filename'])\n",
    "\n",
    "# reduce memory usage\n",
    "df_raw = reduce_mem_usage(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Cycling) (training)meta data indexed features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create features by scaling the wattage derived features by the rider's \"threshold\" for that specific period based on CP Ext. Notice the quotes. This is because there are a multitude of definitions and ways to derive this. We chose to use CP Ext, but other metrics like \"FTP\" could also be used to scale the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 3076.78 MB\n",
      "Decreased by 4.6%\n"
     ]
    }
   ],
   "source": [
    "# First we specifically scale the cumulative variables and in addition create same derived variables as before on raw wattages\n",
    "\n",
    "df_raw['CP_scaled_cum_average_watts'] = np.where((df_raw.cum_average_watts / (df_raw['CP_(Ext)'])) > 0, np.round((df_raw.cum_average_watts / (df_raw['CP_(Ext)']))*100, 0), 0)\n",
    "df_raw['CP_scaled_cum_total_watts'] = np.where((df_raw.cum_total_watts / (df_raw['CP_(Ext)'])) > 0, np.round((df_raw.cum_total_watts / (df_raw['CP_(Ext)']))*100, 0), 0)\n",
    "\n",
    "columns_cum = ['CP_scaled_cum_average_watts', 'CP_scaled_cum_total_watts']\n",
    "\n",
    "for col in columns_cum:\n",
    "    df_raw['log_' + col] = np.log1p(df_raw[col])\n",
    "    df_raw['sqrt_' + col] = np.sqrt(df_raw[col])\n",
    "    df_raw['exp_' + col] = df_raw[col].apply(lambda x: x**(2))\n",
    "    df_raw['cub_' + col] = df_raw[col].apply(lambda x: x**(3))\n",
    "\n",
    "df_raw = reduce_mem_usage(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 3386.39 MB\n",
      "Decreased by 8.4%\n"
     ]
    }
   ],
   "source": [
    "# add scaled wattage variables based on CP ext\n",
    "\n",
    "df_raw['xPower_EMA'] = df_raw['xPower_EMA'].astype(int)\n",
    "df_raw['NP_EMA'] = df_raw['NP_EMA'].astype(int)\n",
    "\n",
    "watts_cols = [x for x in df_raw.columns if x.endswith('sma_watts') \n",
    "    or x.endswith('lag_watts') or x.endswith('ewma_watts') or x.endswith('_EMA') or x =='Average_Power' or x =='Nonzero_Average_Power'] \n",
    "\n",
    "for col in watts_cols:\n",
    "    new_col = 'CP_scaled_' + col\n",
    "    df_raw[new_col] = np.where((df_raw[col] / (df_raw['CP_(Ext)'])) > 0, np.round((df_raw[col] / (df_raw['CP_(Ext)']))*100, 0), 0)\n",
    "\n",
    "# reduce memory usage\n",
    "df_raw = reduce_mem_usage(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this last step we will save the file and use it in our next notebook **3. Feature exploration and selection.ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the file as pickle file\n",
    "\n",
    "df_raw.to_pickle('df_modelset_rider1_4.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
